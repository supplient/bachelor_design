{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Workflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supplient/bachelor_design/blob/no_equal/Workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b417u73oj4fx",
        "colab_type": "code",
        "outputId": "1ce15de8-2269-4176-d692-4d832fae9f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRppCpCXj4f3",
        "colab_type": "text"
      },
      "source": [
        "# Clone repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9NsWrlzj4f3",
        "colab_type": "code",
        "outputId": "cb50639c-5466-4dc5-9e95-ccf6e525e90f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone https://github.com/supplient/bachelor_design.git\n",
        "import os\n",
        "os.chdir(\"bachelor_design\")\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bachelor_design'...\n",
            "remote: Enumerating objects: 153, done.\u001b[K\n",
            "remote: Counting objects: 100% (153/153), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 396 (delta 90), reused 93 (delta 47), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (396/396), 6.02 MiB | 33.30 MiB/s, done.\n",
            "Resolving deltas: 100% (221/221), done.\n",
            "/content/bachelor_design\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFhQQ6Ftj4f7",
        "colab_type": "code",
        "outputId": "3aad4305-98f1-4b01-a0b1-b2cfb185af5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!git checkout no_equal"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Branch 'no_equal' set up to track remote branch 'no_equal' from 'origin'.\n",
            "Switched to a new branch 'no_equal'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmMJ_BUCj4gA",
        "colab_type": "code",
        "outputId": "96646231-23c1-4644-a69e-5db8929bba98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2_ZGa2Hj4gE",
        "colab_type": "text"
      },
      "source": [
        "# Amount GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsvPiovhj4gE",
        "colab_type": "code",
        "outputId": "f2c25e1d-c550-4a0b-fecc-80cb05778d2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from driver_amount import addh"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "[Colab] Using address head: /gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3QpMSuHj4gI",
        "colab_type": "text"
      },
      "source": [
        "# Install python package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdhPhqbsj4gI",
        "colab_type": "code",
        "outputId": "f7c1e9da-d10f-43d5-b03f-42bce19e4366",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "!pip install keras_bert"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_bert\n",
            "  Downloading https://files.pythonhosted.org/packages/ec/08/bffa03eb899b20bfb60553e4503f8bac00b83d415bc6ead08f6b447e8aaa/keras-bert-0.84.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.3.1)\n",
            "Collecting keras-transformer>=0.37.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/2b/c465241bd3f37a3699246827ff4ad7974c6edeaa69cf9cdcff2fd1d3ba46/keras-transformer-0.37.0.tar.gz\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.0.8)\n",
            "Collecting keras-pos-embd>=0.11.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.27.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e6/32/45adf2549450aca7867deccfa04af80a0ab1ca139af44b16bc669e0e09cd/keras-multi-head-0.27.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.14.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Collecting keras-self-attention==0.46.0\n",
            "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.84.0-cp36-none-any.whl size=36139 sha256=c6ea75c84581726fa781492f3fcae4966a4665e97d436663592b40de9c8115ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/59/04/12e95257aebfd27f7edaaf65ab7dd57b5f6cadfb183f1a4ccd\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.37.0-cp36-none-any.whl size=12942 sha256=ea2dc3f86b369a99d3f57b2b066a7982da863818335d9975be7f9bb633a72d3d\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/f9/31/2a3289e948852ce0dd3fcd94c34bbc7eb9628842cb7110a87b\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=6a70e7ed620d9cd42000227e6231ec1a867d4790dd0fc3fe2688f0fda175e9b3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.27.0-cp36-none-any.whl size=15611 sha256=5869a2c6a76ab824f628e4705ba3a299a546413bff8619a461f2f5f1af660237\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/b4/49/0a0c27dcb93c13af02fea254ff51d1a43a924dd4e5b7a7164d\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=0709534bf416fd1f9ddc2e3600a9007dfe01ce1ec0ac78941e9b1e50ea51ed31\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=abc2bc43e6b07c6268725d79cfb3eddb86bd405385e91f8ef9ec9776afbc638c\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=af740661388fa1c6d4df3e740d8aae9930863d2001c38109e4538dc01fc61a39\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=87b87dff176201996dc359f6e68b16752310c045a5329375730ae3f7e09b0550\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
            "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.84.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.27.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.46.0 keras-transformer-0.37.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcnO-auyj4gM",
        "colab_type": "code",
        "outputId": "268cb15c-0713-401a-e9ce-25a3233a6933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-_a_9hl17\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-_a_9hl17\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=f57c7a6c8aaa31892c28605d81705bb61a348944d6e7549ed52c525a1bd9e468\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-r8fy7u4c/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1szxhIu2j4gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/\")\n",
        "lines = []\n",
        "with open(\"crf.py\", \"r\") as fd:\n",
        "  lines = fd.readlines()\n",
        "lines[515] = \"            mask2 = K.cast(K.concatenate([mask, K.cast(K.zeros_like(mask[:, :1]), mask.dtype)], axis=1),\\n\"\n",
        "with open(\"crf.py\", \"w\") as fd:\n",
        "  fd.writelines(lines)\n",
        "\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPzlmOVWj4gX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(\"bachelor_design\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-vRd4iWm113",
        "colab_type": "text"
      },
      "source": [
        "# Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpWZzN3cm5CG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_strs = [\n",
        "\"通过SNMP协议从设备直接采集告警\",\n",
        "\"通过Socket接口从设备直接采集告警\",\n",
        "\"通过Restful服务接口采集告警\",\n",
        "\"通过API接口采集告警\",\n",
        "\"通过网关北向接口采集告警\",\n",
        "\"通过telnet远程登录执行命令并分析返回结果采集告警\",\n",
        "\"通过发送并分析sip信令采集告警\",\n",
        "\"根据大数据指标趋势进行智能预警\",\n",
        "\"根据用户投诉人工录入告警信息\",\n",
        "\"重点号码监控生成的告警信息接入\",\n",
        "\"从各种接口输入的告警数据适配接口协议解析告警信息\",\n",
        "\"标准告警字段及字典定义\",\n",
        "\"告警级别的重新定义\",\n",
        "\"通过把设备标注为工程状态不对此设备产生告警信息\",\n",
        "\"对于已经产生的告警信息可以手工标注为工程告警\",\n",
        "\"核心网告警格式到标准告警格式的映射规则定义\",\n",
        "\"接入网告警格式到标准告警格式的映射规则定义\",\n",
        "\"承载网告警格式到标准告警格式的映射规则定义\",\n",
        "\"核心网告警根据映射规则转换为标准告警\",\n",
        "\"接入网告警根据映射规则转换为标准告警\",\n",
        "\"承载网告警根据映射规则转换为标准告警\",\n",
        "\"原始告警转化为标准告警\",\n",
        "\"定义告警主从关联规则\",\n",
        "\"根据主从规则将符合规则条件的告警建立起主从关系\",\n",
        "\"定义由阈值触发的衍生关联规则阈值参数设置\",\n",
        "\"根据阈值触发的衍生规则将符合规则条件的告警衍生新告警并建立关联关系\",\n",
        "\"定义由同源触发的衍生关联规则阈值参数设置\",\n",
        "\"根据阈值触发的衍生规则将符合规则条件的告警衍生新告警并建立关联关系\",\n",
        "\"网元内部的告警关联关系的建立\",\n",
        "\"网元间告警关联关系的建立\",\n",
        "\"关联关系参数设置\",\n",
        "\"将设备的告警转换成影响业务的告警\",\n",
        "\"以树形的方式按层次呈现告警信息\",\n",
        "\"在网络拓扑图上呈现告警信息\",\n",
        "\"在GIS地图上呈现告警信息\",\n",
        "\"在图表上呈现告警信息\",\n",
        "\"告警流水窗提供对告警属性快速筛选功能并支持多列组合进行筛选多列同时筛选时条件是取与的关系提供自定义筛选过滤的方式可以对一列添加多个筛选条件\",\n",
        "\"将符合条件的告警通过短信推送到运维人员的手机上\",\n",
        "\"以声音闪光的方式提示告警\",\n",
        "\"系统支持设置监控视图各个流水窗口的最大显示告警数量\",\n",
        "\"根据当班人员所关心的专业网元类型等设置窗口显示过滤器将符合设置条件的告警信息以及专业内的关联告警信息分别实时呈现在相应告警子窗口中\",\n",
        "\"告警流水窗支持点击表头可以对该列进行正序和反序的排序功能告警流水窗提供对告警属性快速筛选功能并支持多列组合进行筛选多列同时筛选时条件是取与的关系提供自定义筛选过滤的方式可以对一列添加多个筛选条件\",\n",
        "\"告警流水窗支持点击表头可以对该列进行正序和反序的排序功能告警流水窗提供对告警属性快速筛选功能并支持多列组合进行筛选多列同时筛选时条件是取与的关系提供自定义筛选过滤的方式可以对一列添加多个筛选条件\",\n",
        "\"告警流水窗支持点击表头可以对该列进行正序和反序的排序功能告警流水窗提供对告警属性快速筛选功能并支持多列组合进行筛选多列同时筛选时条件是取与的关系提供自定义筛选过滤的方式可以对一列添加多个筛选条件\",\n",
        "\"为了方便监控人员对选中的告警进行操作系统默认对选择的告警进行屏幕锁定可以用解除锁定按钮来解除屏幕锁定如果选择流水列表中的具体的告警支持多选则锁定所选择告警不影响告警流水列表的告警监控\",\n",
        "\"告警自动确认规则的配置\",\n",
        "\"满足规则的告警自动确认不需要人工确认\",\n",
        "\"人工确认告警\",\n",
        "\"批量进行告警的人工确认\",\n",
        "\"配置自动清除告警的规则\",\n",
        "\"满足自动清除规则的告警自动清除\",\n",
        "\"人工清除告警\",\n",
        "\"人工批量清除告警\",\n",
        "\"根据派单规则设置告警发生后自动派单\",\n",
        "\"不满足派单规则的告警人工进行派单操作\",\n",
        "\"告警工单的流程化处理操作\",\n",
        "\"按照告警类型统计告警生成报表\",\n",
        "\"按照告警级别统计告警生成报表\",\n",
        "\"按照专业统计告警生成报表\",\n",
        "\"按照时间段统计告警生成报表\",\n",
        "\"按照厂家统计告警生成报表\",\n",
        "\"按照地域统计告警生成报表\",\n",
        "\"按照网元统计告警生成报表\",\n",
        "\"统计存在关联关系的告警生成报表\",\n",
        "\"统计自动派单的告警生成报表\",\n",
        "\"统计人工派单的告警生成报表\",\n",
        "\"统计告警派单的处理结果情况生成报表\",\n",
        "\"在省际拓扑视图上展现全业务监测\",\n",
        "\"在省内拓扑视图上展现全业务监测\",\n",
        "\"把网络路由情况展现在拓扑视图上\",\n",
        "\"需要进行巡检的网元范围设定\",\n",
        "\"巡检指标的定义出现次数定义\",\n",
        "\"主要设置巡检的时间频次等内容\",\n",
        "\"查看巡检之后的结果可按照时间段任务名称等进行查询\",\n",
        "\"按照既定格式输出巡检报告\",\n",
        "\"将巡检出的问题通过告警推送\",\n",
        "\"厂家Corba接口私有OMC接口指令文件数据库由采集平台提供实时性能指标数据\",\n",
        "\"性能监控只针对具有实时特性的指标进行监控主要进行24小时内时间粒度为1小时以下含的性能指标进行实时监控\",\n",
        "\"集中性能监控的性能数据是要都要在一个周期内呈现例如800-815的性能数据要在830前呈现如果符合条件则要在830前发出性能告警\",\n",
        "\"进行数据分析\",\n",
        "\"性能数据的存储\",\n",
        "\"自动计算基线和容忍度\",\n",
        "\"手工设置性能指标的阈值区间以此区间范围计算性能指标的级别\",\n",
        "\"多指标关联告警能力说明1告警标题可设置告警的标题名称2告警级别可根据不同条件范围设置不同的告警级别支持四个级别3告警指标对于相同类型同时采集的指标可选择告警条件指标并设置告警条件4网元条件能对告警条件适用的网元范围进行设置网元条件包括厂家地区网元名称不指定则表示对所有符合指标条件的网元进行告警判定5时间条件限定哪些时间点的性能数据进行性能告警判断不指定或全部选择则表示所有时间性能指标进行告警判定6告警正文设置正文中显示内容包括当前kpi指标值\",\n",
        "\"实时性能告警发生后会根据规则自动清除告警清除规则有两种形式1性能指标恢复不满足告警阈值则系统发出性能告警清除消息清除之前发送的性能告警2告警清除观察期性能指标恢复不满足告警阈值并且在一定的时间范围内未再发生恶化则系统发出性能告警消息清除之前发送的性能告警\",\n",
        "\"告警流水视图适用于大数量设备主要应用方式是对于已经产生性能预警的设备进行分析处理对于设备类型多不关注所有设备情况或只关注有告警劣化设备适用进行问题结果监控则采用告警流水方式监控\",\n",
        "\"矩阵监控视图主要用于监控少量重点关注类型设备对于设备类型数量少或小网元挂在大网元下的情况适用按总体结合细节钻取监控可以通过矩阵一屏显示则采用矩阵方式监控\",\n",
        "\"系统提供指标导航树用图表方式显示实时性能指标数据具体功能要求如下1趋势图以曲线方式显示并提供柱图显示切换；2趋势图能够缩放将比较密集集中的内容放大显示；3趋势图提供对比功能可以选择当前系统中存储的历史数据与已经显示的性能数据进行对比；4在矩阵告警详情性能详情告警流水中能够查看相关指标的趋势图；\",\n",
        "\"定义多种开户模板简化开户填写内容\",\n",
        "\"定义有附加属性的业务模板支持快速开通业务\",\n",
        "\"向核心网和接入设备下发开户指令完成开户\",\n",
        "\"下载开户模板导入批量开户数据进行开户操作\",\n",
        "\"向核心网和接入设备下发用户销户指令\",\n",
        "\"对已开户的部门号码进行批量销户操作\",\n",
        "\"修改用户基础信息设置基本通话功能\",\n",
        "\"更换接入设备\",\n",
        "\"用户变更号码\",\n",
        "\"开通修改关闭被叫一号通业务\",\n",
        "\"配置核心网的业务包括各类权限通话功能代答来电显示秘书等业务\",\n",
        "\"将业务工单转换成指令数据向核心网下发\",\n",
        "\"接入设备的适配如TELNETSSHHTTP等方式实现接入设备的开局和增删用户配置\",\n",
        "\"根据业务向接入设备进行下发\",\n",
        "\"开通修改关闭呼叫转移业务\",\n",
        "\"从其他系统资源将通讯录信息同步至服务器\",\n",
        "\"根据排重规则进行通讯录数据排重\",\n",
        "\"添加修改删除单个通讯录数据\",\n",
        "\"按导入模板批量导入通讯录数据\",\n",
        "\"所有的数据进行审核或驳回\",\n",
        "\"提供多种IP话机的协议适配接口支持多种IP话机接入\",\n",
        "\"根据通讯录客户端请求下发全量通讯录数据\",\n",
        "\"根据通讯录客户端请求条件下发增量通讯录数据\",\n",
        "\"接入通讯录服务器的安全认证处理\",\n",
        "\"向通讯录服务器发送全量数据同步请求并存储到本地通讯录\",\n",
        "\"向通讯录服务器发送增量数据同步请求并更新本地通讯录\",\n",
        "\"根据关键字查询本地的通讯录信息\",\n",
        "\"根据Android系统来电通知将来电号码关联出通讯录内的该号码详细信息\",\n",
        "\"放号模板定义了SIP号码的各项配置参数包括注册密码用户密码呼叫权限等在创建号码时关联相应的放号模板可以快速添加号码\",\n",
        "\"单个增加用户号码\",\n",
        "\"按照起止码批量创建号码\",\n",
        "\"系统支持批量导入号码按照提供的Excel模板录入号码信息可以快速创建\",\n",
        "\"批量设置号码IPT权限\",\n",
        "\"修改或者删除号码资源\",\n",
        "\"批量删除号码资源\",\n",
        "\"对各部门的号段进行分配管理\",\n",
        "\"预留号码进行维护\",\n",
        "\"特服号码的维护管理\",\n",
        "\"需要重点保障的号码管理\",\n",
        "\"部门对可用号码资源的查询禁用筛选靓号匹配\",\n",
        "\"部门对已经使用的号码查询\",\n",
        "\"各部门对可用号码可进行禁用授权使用操作\",\n",
        "\"查询经销户后处于冻结期的号码资源\",\n",
        "\"对号码资源的调拨处理部门之间的调拨\",\n",
        "\"按照号码尾号号段靓号规则号码状态等条件进行查询统计\",\n",
        "\"核心网设备资源模型的建立\",\n",
        "\"承载网设备资源模型的建立\",\n",
        "\"接入网设备资源模型的建立\",\n",
        "\"终端设备资源模型的建立\",\n",
        "\"根据资源模型填写参数创建设备\",\n",
        "\"从外部批量导入设备\",\n",
        "\"修改设备参数删除设备\",\n",
        "\"设备之间的关联关系维护\",\n",
        "\"设备的统计查询生成报表\",\n",
        "\"定义用户对象的模型如基本信息设备信息职位信息关联关系等\",\n",
        "\"查询开户销户的所有用户\",\n",
        "\"随时查询某个用户的注册状态\",\n",
        "\"查询使用的设备信息\",\n",
        "\"网管资源模型的建立\",\n",
        "\"各网管参数的维护\",\n",
        "\"网管各个接口的维护\",\n",
        "\"网管各个接口参数的维护\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLuTFsLzj4gZ",
        "colab_type": "text"
      },
      "source": [
        "# Get input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu48rxYSj4ga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from cut_and_tag import load_stopwords, cut_and_remove_stopwords\n",
        "import config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CclSAlXj4ge",
        "colab_type": "code",
        "outputId": "d35e8973-d6ce-441c-b30f-27227690fa61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "stopwords = load_stopwords(addh + config.STOPWORDS_PATH)\n",
        "cut_seqs = []\n",
        "char_seqs = []\n",
        "for input_str in input_strs:\n",
        "    cut_seq = cut_and_remove_stopwords(input_str, stopwords)\n",
        "    cut_seqs.append(cut_seq)\n",
        "    \n",
        "    char_seq = []\n",
        "    for w in cut_seq:\n",
        "        for c in w:\n",
        "            char_seq.append(c)\n",
        "    char_seqs.append(char_seq)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.776 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw-uv7SGj4gi",
        "colab_type": "text"
      },
      "source": [
        "# Load params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyfr-wtRj4gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScZ41c-Mj4gl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_vocab = None\n",
        "with open(addh + config.TAG_VOCAB_PATH, \"r\") as fd:\n",
        "    tag_vocab = json.load(fd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCGrwBedj4hI",
        "colab_type": "text"
      },
      "source": [
        "# Identify function points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAhwHPKCj4hJ",
        "colab_type": "text"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxXOhqigj4hJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49e4516d-d354-4345-a7fe-5a88173f5525"
      },
      "source": [
        "import keras\n",
        "import keras_bert\n",
        "from keras_contrib.layers import CRF"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtlWXqO4j4hN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "43d780b9-918b-4427-d30d-c142fe19cd38"
      },
      "source": [
        "bert_model, bert_model_config = keras_bert.build_model_from_config(\n",
        "    # config_file\n",
        "    addh + config.BERT_CONFIG_PATH, \n",
        "    # settings\n",
        "    training=False, # Not train the whole model. Ignore NSP and MLM\n",
        "    trainable=True\n",
        ")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-hXJUGLj4hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_token = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
        "input_segment = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
        "\n",
        "bert_output = bert_model([input_token, input_segment])\n",
        "\n",
        "crf_model = CRF(len(tag_vocab), sparse_target=True)\n",
        "\n",
        "output = crf_model(bert_output)\n",
        "\n",
        "model = keras.models.Model([input_token, input_segment], output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KbpcIasj4hV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(addh + config.MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3UY6FFij4hY",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWg1e0wUj4hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAeJDOR0j4hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = keras_bert.load_vocabulary(addh + config.BERT_VOCAB_PATH)\n",
        "\n",
        "token_id_seqs = preprocess.preprocess_char(\n",
        "    char_seqs,\n",
        "    vocab,\n",
        "    config.SEQ_LEN,\n",
        "    True\n",
        ")\n",
        "segment_seqs = preprocess.create_segment(\n",
        "    len(token_id_seqs),\n",
        "    len(token_id_seqs[0])\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X_n4Fexj4he",
        "colab_type": "text"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOoGpZipj4hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "completed = False\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9C3Zj66j4hh",
        "colab_type": "code",
        "outputId": "26af91b4-d0de-4b12-b66c-10b3b73be270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "output_one_hot_seqs = None\n",
        "while not completed:\n",
        "    try:\n",
        "        output_one_hot_seqs = model.predict(\n",
        "            [token_id_seqs, segment_seqs],\n",
        "            batch_size = batch_size,\n",
        "            verbose=1\n",
        "        )\n",
        "        completed = True\n",
        "    except tf.errors.ResourceExhaustedError as e:\n",
        "        batch_size = int(batch_size/2)\n",
        "        print(\"Batch Size too large, turn to \" + str(batch_size))\n",
        "        if batch_size < 1:\n",
        "            raise e"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "150/150 [==============================] - 9s 62ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIxzfHTkj4hk",
        "colab_type": "text"
      },
      "source": [
        "## Postprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSNVVzctj4hl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from epoch_checkpoint import judgeWhichTag\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWcyqqAlj4hn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Turn to tag id\n",
        "output_seqs = []\n",
        "for one_hot_seq in output_one_hot_seqs:\n",
        "    one_hot_seq = one_hot_seq[1:-1] # Remove [CLS] and [SEP]\n",
        "    seq = [[np.argmax(x)] for x in one_hot_seq]\n",
        "    output_seqs.append(seq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2H6z3ghj4hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rev_tag_vocab = {}\n",
        "for key, value in tag_vocab.items():\n",
        "    rev_tag_vocab[value] = key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmrpxXopj4hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Judge each output seq's tag\n",
        "output_tags = [judgeWhichTag(seq, rev_tag_vocab) for seq in output_seqs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZnczqnIj4hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count each tag category's number\n",
        "tag_num = {}\n",
        "for tag in output_tags:\n",
        "    num = tag_num.get(tag, 0)\n",
        "    tag_num[tag] = num + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6fv7CtSj4hy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fp_counts = tag_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI57tOS5j4h1",
        "colab_type": "text"
      },
      "source": [
        "# Calculate cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtmX2Sp7j4h1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from funcomo import FUNCOMO"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQ5cnGgj4h4",
        "colab_type": "text"
      },
      "source": [
        "## Set model params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z42BXSrgj4h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cost_model_params = {\n",
        "    \"fp_p\" : FUNCOMO.fp_p,\n",
        "    \"fp_q\" : FUNCOMO.fp_q,\n",
        "    \"VAF\" : [3, 3, 3,\n",
        "          3, 3, 3,\n",
        "          3, 3, 3,\n",
        "          3, 3, 3,\n",
        "          3, 3,],\n",
        "\n",
        "    \"lang_factor\" : FUNCOMO.lang_factor[\"C++\"],\n",
        "\n",
        "    \"develop_mode_factor\" : FUNCOMO.develop_mode_factor[\"semi-detached\"],\n",
        "    \"EAF\" : {\n",
        "          \"required software reliability\": 1.15,\n",
        "          \"run-time performance constraints\": 1.11,\n",
        "          \"analyst capaility\": 0.86,\n",
        "          \"applications experience\": 0.82,\n",
        "          \"required development schedule\": 1.04,\n",
        "    },\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ-KbUMcj4h8",
        "colab_type": "text"
      },
      "source": [
        "## Use cost model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inlt8ezoj4h9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cmp = cost_model_params\n",
        "\n",
        "AFP = FUNCOMO.FP2AFP(\n",
        "    fp_counts,\n",
        "    cmp[\"fp_p\"],\n",
        "    cmp[\"fp_q\"],\n",
        "    cmp[\"VAF\"],\n",
        ")\n",
        "\n",
        "KLOC = FUNCOMO.scale2KLOC(\n",
        "    AFP,\n",
        "    cmp[\"lang_factor\"],\n",
        ")\n",
        "\n",
        "PM = FUNCOMO.KLOC2PM(\n",
        "    KLOC,\n",
        "    cmp[\"develop_mode_factor\"][0],\n",
        "    cmp[\"develop_mode_factor\"][1],\n",
        "    cmp[\"EAF\"],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQj0xpaZj4iE",
        "colab_type": "text"
      },
      "source": [
        "## Output result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJhI1MZ-j4iE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import PrettyPrinter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3WmHTmzj4iJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pp = PrettyPrinter(indent = 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbzmiesMj4iL",
        "colab_type": "code",
        "outputId": "97b2e7f3-6821-4369-b872-63d7465dc6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print(\"Using params: \")\n",
        "pp.pprint(cost_model_params)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using params: \n",
            "{   'EAF': {   'analyst capaility': 0.86,\n",
            "               'applications experience': 0.82,\n",
            "               'required development schedule': 1.04,\n",
            "               'required software reliability': 1.15,\n",
            "               'run-time performance constraints': 1.11},\n",
            "    'VAF': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
            "    'develop_mode_factor': (3.0, 1.12),\n",
            "    'fp_p': 0.65,\n",
            "    'fp_q': 0.01,\n",
            "    'lang_factor': 0.064}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJI4UObAj4iO",
        "colab_type": "code",
        "outputId": "2dad4943-f4c1-48e7-9866-261d8b0db727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"Result: \")\n",
        "pp.pprint({\n",
        "    \"KLOC\": KLOC,\n",
        "    \"PM\": PM,\n",
        "})"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Result: \n",
            "{'KLOC': 10.272, 'PM': 38.154110117576785}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}