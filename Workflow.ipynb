{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/supplient/bachelor_design.git\n",
    "import os\n",
    "os.chdir(\"bachelor_design\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout equal_realize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amount GDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from driver_amount import addh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/\")\n",
    "lines = []\n",
    "with open(\"crf.py\", \"r\") as fd:\n",
    "  lines = fd.readlines()\n",
    "lines[515] = \"            mask2 = K.cast(K.concatenate([mask, K.cast(K.zeros_like(mask[:, :1]), mask.dtype)], axis=1),\\n\"\n",
    "with open(\"crf.py\", \"w\") as fd:\n",
    "  fd.writelines(lines)\n",
    "\n",
    "os.chdir(\"/content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"bachelor_design\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cut_and_tag import load_stopwords, cut_and_remove_stopwords\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_strs = None\n",
    "# TODO load input_strs\n",
    "\n",
    "stopwords = load_stopwords(addh + config.STOPWORDS_PATH)\n",
    "cut_seqs = []\n",
    "char_seqs = []\n",
    "for input_str in input_strs:\n",
    "    cut_seq = cut_and_remove_stopwords(input_str, stopwords)\n",
    "    cut_seqs.append(cut_seq)\n",
    "    \n",
    "    char_seq = []\n",
    "    for w in cut_seq:\n",
    "        for c in w:\n",
    "            char_seq.append(c)\n",
    "    char_seqs.append(char_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vocab = None\n",
    "with open(addh + config.TAG_VOCAB_PATH, \"r\") as fd:\n",
    "    tag_vocab = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_params = None\n",
    "with open(addh + config.EQUAL_PARAM_PATH, \"r\") as fd:\n",
    "    equal_params = json.load(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from char_emb import CharEmbedder\n",
    "from SIF import SIF\n",
    "from dist_cal import DistCal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_method = \"sum_last_four\"\n",
    "dist_method = \"cos\"\n",
    "dist_theta = equal_params[dist_method + \"_theta\"] # TODO edit equal params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embedder = CharEmbedder()\n",
    "sif = SIF(params[\"sif_alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_emb_seqs = char_embedder.embed(char_seqs, emb_method)\n",
    "sen_vecs = sif.compose(cut_seqs, char_seqs, char_emb_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cal similarity and remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_cal = DistCal(sen_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sen_vecs)-1):\n",
    "    if i in removed_index:\n",
    "        continue\n",
    "    for j in range(i+1, len(sen_vecs)):\n",
    "        if j in removed_index:\n",
    "            continue\n",
    "        \n",
    "        dist = dist_cal.cal(sen_vecs[i], sen_vecs[j], dist_method)\n",
    "        if dist < dist_theta:\n",
    "            removed_index.push(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_char_seqs = []\n",
    "for i in range(len(char_seqs)):\n",
    "    if i in removed_index:\n",
    "        continue\n",
    "    new_char_seqs.push(char_seqs[i])\n",
    "char_seqs = new_char_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify function points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_bert\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model, bert_model_config = keras_bert.build_model_from_config(\n",
    "    # config_file\n",
    "    addh + config.BERT_CONFIG_PATH, \n",
    "    # settings\n",
    "    training=False, # Not train the whole model. Ignore NSP and MLM\n",
    "    trainable=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
    "input_segment = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
    "\n",
    "bert_output = bert_model([input_token, input_segment])\n",
    "\n",
    "crf_model = CRF(len(tag_vocab), sparse_target=True)\n",
    "\n",
    "output = crf_model(bert_output)\n",
    "\n",
    "model = keras.models.Model([input_token, input_segment], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(addh + config.MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = keras_bert.load_vocabulary(addh + config.BERT_VOCAB_PATH)\n",
    "\n",
    "token_id_seqs = preprocess.preprocess_char(\n",
    "    char_seqs,\n",
    "    vocab,\n",
    "    config.SEQ_LEN,\n",
    "    True\n",
    ")\n",
    "segment_seqs = preprocess.create_segment(\n",
    "    len(token_id_seqs),\n",
    "    len(token_id_seqs[0])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "completed = False\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_one_hot_seqs = None\n",
    "while not completed:\n",
    "    try:\n",
    "        output_one_hot_seqs = model.predict(\n",
    "            [token_id_seqs, segment_seqs],\n",
    "            batch_size = batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        completed = True\n",
    "    except tf.errors.ResourceExhaustedError as e:\n",
    "        batch_size = int(batch_size/2)\n",
    "        print(\"Batch Size too large, turn to \" + str(batch_size))\n",
    "        if batch_size < 1:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from epoch_checkpoint import judgeWhichTag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn to tag id\n",
    "output_seqs = []\n",
    "for one_hot_seq in output_one_hot_seqs:\n",
    "    one_hot_seq = one_hot_seq[1:-1] # Remove [CLS] and [SEP]\n",
    "    seq = [[np.argmax(x)] for x in one_hot_seq]\n",
    "    output_seqs.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_tag_vocab = {}\n",
    "for key, value in tag_vocab.items():\n",
    "    rev_tag_vocab[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judge each output seq's tag\n",
    "output_tags = [judgeWhichTag(seq, rev_tag_vocab) for seq in output_seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count each tag category's number\n",
    "tag_num = {}\n",
    "for tag in output_tags:\n",
    "    num = tag_num.get(tag, 0)\n",
    "    tag_num[tag] = num + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_counts = tag_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcomo import FUNCOMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_model_params = {\n",
    "    \"fp_p\" : FUNCOMO.fp_p,\n",
    "    \"fp_q\" : FUNCOMO.fp_q,\n",
    "    \"VAF\" : [2, 2],\n",
    "\n",
    "    \"lang\" : \"C++\",\n",
    "    \"lang_factor\" : FUNCOMO.lang_factor[lang],\n",
    "\n",
    "    \"develop_mode\" : \"semi_detached\",\n",
    "    \"develop_mode_factor\" : FUNCOMO.develop_mode_factor[develop_mode],\n",
    "    \"em\" : \"early_design\",\n",
    "    \"em_factor\" : FUNCOMO.EM_factor[em],\n",
    "    \"KLOC_p\" : FUNCOMO.KLOC.p,\n",
    "    \"KLOC_q\" : FUNCOMO.KLOC.q,\n",
    "    \"w\" : [2, 2, 2, 2, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = cost_model_params\n",
    "\n",
    "scale = FUNCOMO.FP2Scale(\n",
    "    fp_counts,\n",
    "    cmp[\"fp_p\"],\n",
    "    cmp[\"fp_q\"],\n",
    "    cmp[\"VAF\"],\n",
    ")\n",
    "\n",
    "KLOC = FUNCOMO.scale2KLOC(\n",
    "    cmp[\"scale\"],\n",
    "    cmp[\"lang_factor\"],\n",
    ")\n",
    "\n",
    "PM = FUNCOMO.KLOC2PM(\n",
    "    cmp[\"KLOC\"],\n",
    "    cmp[\"develop_mode_factor\"],\n",
    "    cmp[\"em_factor\"],\n",
    "    cmp[\"KLOC_p\"],\n",
    "    cmp[\"KLOC_q\"],\n",
    "    cmp[\"w\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = PrettyPrinter(indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using params: \")\n",
    "pp.pprint(cost_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Result: \")\n",
    "pp.pprint({\n",
    "    \"KLOC\": KLOC,\n",
    "    \"PM\": PM,\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
