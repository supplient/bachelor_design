{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/supplient/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/supplient/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import jieba\n",
    "import re\n",
    "import types\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.merge import concatenate, add, multiply\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "import io\n",
    "import sys\n",
    "import urllib.request\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建停用词list  \n",
    "def stopwordslist(stop_file):  \n",
    "    stopwords = [line.strip() for line in open(stop_file, 'r').readlines()]  \n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_word_edit(lhs, rhs):\n",
    "    len_1 = len(lhs)\n",
    "    len_2 = len(rhs)\n",
    "    dist_table = [[0] * (len_2 + 1) for i in range(len_1 + 1)]\n",
    "    for i in range(len_1 + 1):\n",
    "        dist_table[i][0] = i\n",
    "    for j in range(len_2 + 1):\n",
    "        dist_table[0][j] = j\n",
    "    for i in range(1, len_1 + 1):\n",
    "        for j in range(1, len_2 + 1):\n",
    "            if lhs[i - 1] == rhs[j - 1]:\n",
    "                cost = 0\n",
    "            else:\n",
    "                cost = 1\n",
    "            deletion = dist_table[i - 1][j] + 1\n",
    "            insertion = dist_table[i][j - 1] + 1\n",
    "            substitution = dist_table[i - 1][j - 1] + cost\n",
    "            dist_table[i][j] = min(min(deletion, insertion), substitution)\n",
    "    return dist_table[len_1][len_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对句子进行分词;赋予标签\n",
    "def seg_sentence(input_file, log_file, stop_file, segwithoutlabel_file):\n",
    "    words = []\n",
    "    labels = []\n",
    "    text1 = []\n",
    "    outstr=''\n",
    "    stopwords = stopwordslist(stop_file)  # 这里加载停用词的路径  \n",
    "    outf = open(log_file, 'w', encoding='utf-8', errors='ignore')\n",
    "    outft = open(segwithoutlabel_file, 'w', encoding='utf-8', errors='ignore')\n",
    "    with open(input_file,'r', encoding='utf-8', errors='ignore') as inf:\n",
    "        for line in inf.readlines():\n",
    "            line = line.strip()\n",
    "            # print (\"line:\",line)\n",
    "            if line:\n",
    "                t_vec = line.split('\\t')\n",
    "                if len(t_vec) >= 3:\n",
    "                    dec = t_vec[0]\n",
    "                    dec = dec.strip()\n",
    "                    count_name = t_vec[1]\n",
    "                    label = str(t_vec[2])\n",
    "                    if label == 'ILf':\n",
    "                        label = 'ILF'\n",
    "                    if label == 'EIf':\n",
    "                        label = 'EIF'\n",
    "                else:\n",
    "                    continue\n",
    "            labels.append(label)\n",
    "            # print (\"dec\", dec)\n",
    "            # print (\"count_name\", count_name)\n",
    "            # print (\"label\", label)\n",
    "            sentence_seged = jieba.cut(dec)\n",
    "            count_seged = jieba.cut(count_name)\n",
    "            sentence_result = []\n",
    "            count_result = []\n",
    "            for word in sentence_seged:\n",
    "                sentence_result.append(word)\n",
    "            for count_word in count_seged:\n",
    "                count_result.append(count_word)\n",
    "            text2 = []\n",
    "            # print (\"sentence_result\", sentence_result)\n",
    "            # print (\"count_result\", count_result)\n",
    "            for word in sentence_result:\n",
    "                flag = 'O'\n",
    "                text1 = []\n",
    "                if word not in stopwords:\n",
    "                    #print (\"stopwords\")\n",
    "                    if word != '\\t' and word != '' and word != ' ':\n",
    "                        #print (\"kongbai\")\n",
    "                        for count_e in count_result:\n",
    "                            #print (\"daozhelile\")\n",
    "                            if count_e == '':\n",
    "                                #print (\"count_word\", count_e)\n",
    "                                continue\n",
    "                            else:\n",
    "                                if word == count_e:\n",
    "                                    flag = label\n",
    "                                    break\n",
    "                                else:\n",
    "                                    # print (\"word\", word)\n",
    "                                    # print (\"count_word\", count_e)\n",
    "                                    # print (\"length\", len(count_e))\n",
    "                                    dist = cal_word_edit(word, count_e)\n",
    "                                    min_len = min(len(word), len(count_e))\n",
    "                                    if min_len <= 3:\n",
    "                                        if dist < 2:\n",
    "                                            flag = label\n",
    "                                            break\n",
    "                                    elif min_len <= 7:\n",
    "                                        if dist < 3:\n",
    "                                            flag = label\n",
    "                                            break\n",
    "                                    else:\n",
    "                                        if dist < 4:\n",
    "                                            flag = label\n",
    "                                            break\n",
    "                        i = 0\n",
    "                        for str_tmp in word:\n",
    "                            if flag == 'O':\n",
    "                                str_flag = 'O'\n",
    "                            elif i == 0:\n",
    "                                str_flag = 'B' + '-' + flag\n",
    "                            else:\n",
    "                                str_flag = 'I' + '-' + flag\n",
    "                            i += 1\n",
    "                            text1.append(str_tmp)\n",
    "                            text1.append(str_flag)\n",
    "                            text2.append(str_tmp)\n",
    "                            outstr = str_tmp.strip()\n",
    "                            outstr = outstr.strip(' ')\n",
    "                            outf.write(outstr)\n",
    "                            outft.write(outstr)\n",
    "                            outf.write(\" \")\n",
    "                            outft.write(\" \")\n",
    "                            outf.write(str_flag)\n",
    "                            outf.write(\"\\n\")\n",
    "            outf.write(\"]\")\n",
    "            outf.write(\"\\n\")\n",
    "                        #print (\"line:\",outstr)\n",
    "    outf.close()\n",
    "    outft.close()\n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale = True\n",
    "addh = \"\"\n",
    "if locale:\n",
    "    addh = \"/mnt/d\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 1.173 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "train_text=seg_sentence(\n",
    "    addh+'/My Drive/Graduation/old/实验/summary_2.txt',\n",
    "    addh+'/My Drive/Graduation/old/实验/test_data_e.data',\n",
    "    addh+'/My Drive/Graduation/old/实验/stopwords.txt',\n",
    "    addh+'/My Drive/Graduation/old/实验/segwithoutlabel_file.txt'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
