{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supplient/bachelor_design/blob/equal_realize/Continue_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ErojEaZ-86B-"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT5WyBWP3m0-",
        "colab_type": "code",
        "outputId": "4d7001b7-6c14-48ce-dd8f-c29d0630cae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ntV4sZB_8kBc",
        "outputId": "56d3a3da-6655-4aaa-d177-27a3793d502e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone https://github.com/supplient/bachelor_design.git\n",
        "import os\n",
        "os.chdir(\"bachelor_design\")\n",
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bachelor_design'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 362 (delta 71), reused 76 (delta 40), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (362/362), 5.99 MiB | 6.90 MiB/s, done.\n",
            "Resolving deltas: 100% (202/202), done.\n",
            "/content/bachelor_design\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4uVkxeL8uOL",
        "outputId": "0b1ebd50-b1d9-4e8b-ae34-4a19400df7e2",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!git checkout equal_realize\n",
        "!git pull"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Branch 'equal_realize' set up to track remote branch 'equal_realize' from 'origin'.\n",
            "Switched to a new branch 'equal_realize'\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gdgaaQWTo_Qm"
      },
      "source": [
        "# Mount GDriver\n",
        "Perpare Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XuNfDlfh4v4-",
        "outputId": "0f7df785-6ffb-4af7-f578-1defcd675fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from driver_amount import addh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "[Colab] Using address head: /gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nGqJ3bOy8fGg",
        "outputId": "515650cd-a423-4685-821e-bf9f227b068e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "!pip install keras_bert"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_bert\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/0f/cdc886c1018943ea62d3209bc964413d5aa9d0eb7e493abd8545be679294/keras-bert-0.81.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.18.2)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.3.1)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/54/0c/fede535ac576c03863c44bf2e0bf051fe21f5e10103631b6b6236ae446f3/keras-transformer-0.32.0.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (2.10.0)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.81.0-cp36-none-any.whl size=37913 sha256=d5639f2194b2c0c01d925a1b2ed50178fff40c6d5ac6974c37e71b2392a80abc\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/27/da/ffc2d573aa48b87440ec4f98bc7c992e3a2d899edb2d22ef9e\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.32.0-cp36-none-any.whl size=13266 sha256=b6fc48b23e6de28023370956bea2f88753099763f62fad41d7a13cd9f5d82de3\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f0/ce/82fa5d024d5ef8e263f26a50dcee23820efe245680ce9c922a\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=ac6b97dbd3853d0038aab19eae07d09b55990d698a01183d2188aaed7a2c6fed\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=6e9f3a63b4aba1a8b2c8dffae87975e4fc519a14e85710c954946ae70ea7b4ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=8c23e83647db8d0945e4a7fbcdf47b9e588693ffa49fc2cfc1519093c9d75055\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=c6910b3ca98e30d3a01713afb1c9b12a48835ccdf6f135723e7b3648e50f83f9\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=fb0422013abb0b45842c96483f300cd88c5d983b010bfcfc6df052725e8ef50c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=306ac55252ab5fa9c595421b0a458c6767a5a69a60592b3356e70bf07adf9d83\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.81.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.32.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "smZ4TyF0f64H",
        "outputId": "c41e4e01-9d36-4209-d868-b68a6c690593",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-0vp2puw1\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-0vp2puw1\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.3.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=fc1d0e5dbfde304986c1a8f66ca6f02099d331a9f431d64e6ea5057c85aadba3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0q6taqlu/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw7z_zzNgaSo",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/\")\n",
        "lines = []\n",
        "with open(\"crf.py\", \"r\") as fd:\n",
        "  lines = fd.readlines()\n",
        "lines[515] = \"            mask2 = K.cast(K.concatenate([mask, K.cast(K.zeros_like(mask[:, :1]), mask.dtype)], axis=1),\\n\"\n",
        "with open(\"crf.py\", \"w\") as fd:\n",
        "  fd.writelines(lines)\n",
        "\n",
        "os.chdir(\"/content\")\n",
        "os.chdir(\"bachelor_design\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DBCO9_n6abM",
        "colab_type": "text"
      },
      "source": [
        "# Load Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt34yXgY6dUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_LJ3yrB6y2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_vocab = None\n",
        "with open(addh + config.TAG_VOCAB_PATH, \"r\") as fd:\n",
        "  tag_vocab = json.load(fd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yKeEl1EWo_Q6"
      },
      "source": [
        "# Prepare Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "318x_FrYo_Q8",
        "colab": {}
      },
      "source": [
        "from cut_and_tag import cut_and_tag\n",
        "import preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nb-5so9mo_RC",
        "outputId": "38a7ded0-1655-4bb4-82e9-73b291e7fb05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "cut_seqs, char_seqs, tag_seqs = cut_and_tag(\n",
        "    addh + config.DATA_PATH,\n",
        "    addh + config.STOPWORDS_PATH\n",
        ")\n",
        "char_seqs, tag_seqs = preprocess.shuffle_twin(\n",
        "    char_seqs,\n",
        "    tag_seqs\n",
        ")\n",
        "token_id_seqs, segment_seqs, tag_id_seqs, tag_vocab = preprocess.preprocess(\n",
        "    char_seqs, \n",
        "    tag_seqs,\n",
        "    addh + config.BERT_VOCAB_PATH,\n",
        "    SEQ_LEN=config.SEQ_LEN,\n",
        "    tag_vocab=tag_vocab\n",
        "    )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.774 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je_ajx6J2ml4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split train and text\n",
        "train_num = int(len(token_id_seqs) * 0.9)\n",
        "\n",
        "test_token_id_seqs = token_id_seqs[train_num:]\n",
        "test_segment_seqs = segment_seqs[train_num:]\n",
        "test_tag_id_seqs = tag_id_seqs[train_num:]\n",
        "\n",
        "train_token_id_seqs = token_id_seqs[0:train_num]\n",
        "train_segment_seqs = segment_seqs[0:train_num]\n",
        "train_tag_id_seqs = tag_id_seqs[0:train_num]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XLj4Kcwko_RW",
        "outputId": "1dd33b2a-8d47-4db6-d336-facf9e2baf2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "tag_vocab"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " 'B-EI': 2,\n",
              " 'B-EIF': 10,\n",
              " 'B-EO': 4,\n",
              " 'B-EQ': 8,\n",
              " 'B-ILF': 6,\n",
              " 'I-EI': 3,\n",
              " 'I-EIF': 11,\n",
              " 'I-EO': 5,\n",
              " 'I-EQ': 9,\n",
              " 'I-ILF': 7,\n",
              " 'O': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wv1zgY3lo_Rb"
      },
      "source": [
        "# Build Model\n",
        "using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QVZYwuGro_Rc",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras_bert "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tBszsRPVo_Rh",
        "outputId": "e4671a4d-aaa6-4909-ee8a-82d6e2294e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "bert_model, bert_model_config = keras_bert.build_model_from_config(\n",
        "    # config_file\n",
        "    addh + config.BERT_CONFIG_PATH, \n",
        "    # settings\n",
        "    training=False, # Not train the whole model. Ignore NSP and MLM\n",
        "    trainable=True\n",
        ")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KRVUQ-dDfW0F",
        "colab": {}
      },
      "source": [
        "from keras_contrib.layers import CRF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7riudikwo_Rm",
        "colab": {}
      },
      "source": [
        "input_token = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
        "input_segment = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
        "\n",
        "bert_output = bert_model([input_token, input_segment])\n",
        "\n",
        "crf_model = CRF(len(tag_vocab), sparse_target=True)\n",
        "\n",
        "output = crf_model(bert_output)\n",
        "\n",
        "model = keras.models.Model([input_token, input_segment], output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux9lxZyJ2mmO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(addh + config.MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt34Q-VO2mmR",
        "colab_type": "text"
      },
      "source": [
        "# Load train record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bjsOu942mmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open(addh + config.TRAIN_REC_PATH, \"r\") as fd:\n",
        "    train_rec = json.load(fd)\n",
        "last_epoch = 0\n",
        "if len(train_rec) > 1:\n",
        "    last_epoch = train_rec[-1][\"epoch\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1NnstgM3o_Rx"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZnpZmJ9o_Ry",
        "outputId": "f4850070-2b4f-4ba9-c44a-0ef5b08e6f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(lr=0.00004),\n",
        "    loss=crf_model.loss_function,\n",
        "    metrics=[crf_model.accuracy]\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KFQwbTXw4v6G",
        "colab": {}
      },
      "source": [
        "import epoch_checkpoint\n",
        "epoch_callback = epoch_checkpoint.EpochCheckpoint(\n",
        "    addh + config.MODEL_PATH,\n",
        "    addh + config.TRAIN_REC_PATH,\n",
        "    1,\n",
        "    [test_token_id_seqs, test_segment_seqs],\n",
        "    test_tag_id_seqs,\n",
        "    tag_vocab\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3wC8aDwfJLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "completed = False\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fiWLYOZHo_R3",
        "outputId": "7e4216c2-cb94-4f64-abbc-a6723254b3ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while not completed:\n",
        "  try:\n",
        "    model.fit(\n",
        "        x=[train_token_id_seqs, train_segment_seqs],\n",
        "        y=[train_tag_id_seqs], \n",
        "        batch_size=batch_size,\n",
        "        initial_epoch=last_epoch+1,\n",
        "        epochs=train_rec[0][\"train_params\"][\"epochs\"],\n",
        "        verbose=1,\n",
        "        validation_data=[[test_token_id_seqs, test_segment_seqs], [test_tag_id_seqs]],\n",
        "        callbacks=[epoch_callback]\n",
        "    )\n",
        "    completed = True\n",
        "  except tf.errors.ResourceExhaustedError as e:\n",
        "    batch_size = int(batch_size/2)\n",
        "    print(\"Batch Size too large, turn to \" + str(batch_size))\n",
        "    if batch_size < 1:\n",
        "      raise e"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7005 samples, validate on 779 samples\n",
            "Epoch 11/30\n",
            "Batch Size too large, turn to 8\n",
            "Train on 7005 samples, validate on 779 samples\n",
            "Epoch 11/30\n",
            "7005/7005 [==============================] - 1242s 177ms/step - loss: 55.6326 - crf_viterbi_accuracy: 0.9624 - val_loss: 54.6435 - val_crf_viterbi_accuracy: 0.9556\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 55s 70ms/step\n",
            "Updating train record...\n",
            "Epoch 12/30\n",
            "7005/7005 [==============================] - 1261s 180ms/step - loss: 55.6139 - crf_viterbi_accuracy: 0.9662 - val_loss: 54.6478 - val_crf_viterbi_accuracy: 0.9664\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 52s 67ms/step\n",
            "Updating train record...\n",
            "Epoch 13/30\n",
            "7005/7005 [==============================] - 1242s 177ms/step - loss: 55.6106 - crf_viterbi_accuracy: 0.9653 - val_loss: 54.6606 - val_crf_viterbi_accuracy: 0.9559\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 51s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 14/30\n",
            "7005/7005 [==============================] - 1237s 177ms/step - loss: 55.6031 - crf_viterbi_accuracy: 0.9706 - val_loss: 54.6697 - val_crf_viterbi_accuracy: 0.9627\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 51s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 15/30\n",
            "7005/7005 [==============================] - 1236s 177ms/step - loss: 55.6024 - crf_viterbi_accuracy: 0.9726 - val_loss: 54.6844 - val_crf_viterbi_accuracy: 0.9503\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 50s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 16/30\n",
            "7005/7005 [==============================] - 1235s 176ms/step - loss: 55.5951 - crf_viterbi_accuracy: 0.9723 - val_loss: 54.6752 - val_crf_viterbi_accuracy: 0.9547\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 50s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 17/30\n",
            "7005/7005 [==============================] - 1238s 177ms/step - loss: 55.5963 - crf_viterbi_accuracy: 0.9717 - val_loss: 54.7300 - val_crf_viterbi_accuracy: 0.9494\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 51s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 18/30\n",
            "7005/7005 [==============================] - 1236s 176ms/step - loss: 55.5957 - crf_viterbi_accuracy: 0.9713 - val_loss: 54.7140 - val_crf_viterbi_accuracy: 0.9515\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 51s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 19/30\n",
            "7005/7005 [==============================] - 1239s 177ms/step - loss: 55.5947 - crf_viterbi_accuracy: 0.9704 - val_loss: 54.7127 - val_crf_viterbi_accuracy: 0.9490\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 50s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 20/30\n",
            "7005/7005 [==============================] - 1237s 177ms/step - loss: 55.5891 - crf_viterbi_accuracy: 0.9740 - val_loss: 54.7372 - val_crf_viterbi_accuracy: 0.9526\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 51s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 21/30\n",
            "7005/7005 [==============================] - 1266s 181ms/step - loss: 55.5845 - crf_viterbi_accuracy: 0.9760 - val_loss: 54.7501 - val_crf_viterbi_accuracy: 0.9499\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 53s 68ms/step\n",
            "Updating train record...\n",
            "Epoch 22/30\n",
            "7005/7005 [==============================] - 1278s 182ms/step - loss: 55.5874 - crf_viterbi_accuracy: 0.9742 - val_loss: 54.7379 - val_crf_viterbi_accuracy: 0.9534\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 52s 67ms/step\n",
            "Updating train record...\n",
            "Epoch 23/30\n",
            "7005/7005 [==============================] - 1254s 179ms/step - loss: 55.5924 - crf_viterbi_accuracy: 0.9746 - val_loss: 54.7438 - val_crf_viterbi_accuracy: 0.9424\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 51s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 24/30\n",
            "7005/7005 [==============================] - 1238s 177ms/step - loss: 55.5859 - crf_viterbi_accuracy: 0.9749 - val_loss: 54.7300 - val_crf_viterbi_accuracy: 0.9536\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 51s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 25/30\n",
            "7005/7005 [==============================] - 1249s 178ms/step - loss: 55.5840 - crf_viterbi_accuracy: 0.9758 - val_loss: 54.7721 - val_crf_viterbi_accuracy: 0.9470\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 50s 65ms/step\n",
            "Updating train record...\n",
            "Epoch 26/30\n",
            "7005/7005 [==============================] - 1219s 174ms/step - loss: 55.5861 - crf_viterbi_accuracy: 0.9753 - val_loss: 54.7791 - val_crf_viterbi_accuracy: 0.9410\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 50s 64ms/step\n",
            "Updating train record...\n",
            "Epoch 27/30\n",
            "4336/7005 [=================>............] - ETA: 7:27 - loss: 55.5031 - crf_viterbi_accuracy: 0.9748"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zp-wuH9RBk3r",
        "colab": {}
      },
      "source": [
        "model.save(addh + config.MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}