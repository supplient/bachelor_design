{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supplient/bachelor_design/blob/equal_realize/Continue_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ErojEaZ-86B-"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT5WyBWP3m0-",
        "colab_type": "code",
        "outputId": "90d4f4fd-25b1-487d-904a-2e267936dd2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nGqJ3bOy8fGg",
        "outputId": "69ac2fb2-dfae-421f-878c-b2f7442fdf3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        }
      },
      "source": [
        "!pip install keras_bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_bert\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/0f/cdc886c1018943ea62d3209bc964413d5aa9d0eb7e493abd8545be679294/keras-bert-0.81.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_bert) (1.18.2)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_bert) (2.2.5)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/54/0c/fede535ac576c03863c44bf2e0bf051fe21f5e10103631b6b6236ae446f3/keras-transformer-0.32.0.tar.gz\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_bert) (1.12.0)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.81.0-cp36-none-any.whl size=37913 sha256=4f5a7e1c9ce3b3816ec8c60935d8fd614cc262f5876e36d6847151adc425cb8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/27/da/ffc2d573aa48b87440ec4f98bc7c992e3a2d899edb2d22ef9e\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.32.0-cp36-none-any.whl size=13266 sha256=2d534f7c8cf74e2c4157994ef75c6d3032f133f8b28ba55c4a44986d6cafc7e2\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f0/ce/82fa5d024d5ef8e263f26a50dcee23820efe245680ce9c922a\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=1787c123607bab7a30c987c72c6d0201e48a62949ec562619b0982a090045267\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=e73ddcf89550b44685d37bf9c337d65dda418ccd7dcd071f852de442b1989096\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=074a9c58bcba019f182b2381b42a8d348e980f2b2bda5ee732b14b27754345af\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=a7115a7c22c73e1b71b3de07bbb8dbf424cf2bc451ccaa434c68d71df6643184\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=28edc4e8af88f5421f70ff40a8584e6da2ff5bbb735228a7cf78a5fc6520cde7\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=c7b900e28c15ffb5530b40e7247d94e02ca216f09eed2aa4a9c7980a248ae94c\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built keras-bert keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "Installing collected packages: keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.81.0 keras-embed-sim-0.7.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.32.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "smZ4TyF0f64H",
        "outputId": "2060b8bc-aadd-4927-aede-750a08c9113c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-ic5oj11p\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-ic5oj11p\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-contrib==2.0.8) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.18.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-contrib==2.0.8) (2.10.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-cp36-none-any.whl size=101064 sha256=b1134ebabb21e47d4c407475da0728b218a82592f6b82473e746d1275f8cdb3f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-a_jv35bp/wheels/11/27/c8/4ed56de7b55f4f61244e2dc6ef3cdbaff2692527a2ce6502ba\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jw7z_zzNgaSo",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/\")\n",
        "lines = []\n",
        "with open(\"crf.py\", \"r\") as fd:\n",
        "  lines = fd.readlines()\n",
        "lines[515] = \"            mask2 = K.cast(K.concatenate([mask, K.cast(K.zeros_like(mask[:, :1]), mask.dtype)], axis=1),\\n\"\n",
        "with open(\"crf.py\", \"w\") as fd:\n",
        "  fd.writelines(lines)\n",
        "\n",
        "os.chdir(\"/content\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ntV4sZB_8kBc",
        "outputId": "8a0b0538-d4d4-4c14-e0a1-bdd642c4393d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone https://github.com/supplient/bachelor_design.git\n",
        "import os\n",
        "os.chdir(\"bachelor_design\")\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bachelor_design'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/85)\u001b[K\rremote: Counting objects:   2% (2/85)\u001b[K\rremote: Counting objects:   3% (3/85)\u001b[K\rremote: Counting objects:   4% (4/85)\u001b[K\rremote: Counting objects:   5% (5/85)\u001b[K\rremote: Counting objects:   7% (6/85)\u001b[K\rremote: Counting objects:   8% (7/85)\u001b[K\rremote: Counting objects:   9% (8/85)\u001b[K\rremote: Counting objects:  10% (9/85)\u001b[K\rremote: Counting objects:  11% (10/85)\u001b[K\rremote: Counting objects:  12% (11/85)\u001b[K\rremote: Counting objects:  14% (12/85)\u001b[K\rremote: Counting objects:  15% (13/85)\u001b[K\rremote: Counting objects:  16% (14/85)\u001b[K\rremote: Counting objects:  17% (15/85)\u001b[K\rremote: Counting objects:  18% (16/85)\u001b[K\rremote: Counting objects:  20% (17/85)\u001b[K\rremote: Counting objects:  21% (18/85)\u001b[K\rremote: Counting objects:  22% (19/85)\u001b[K\rremote: Counting objects:  23% (20/85)\u001b[K\rremote: Counting objects:  24% (21/85)\u001b[K\rremote: Counting objects:  25% (22/85)\u001b[K\rremote: Counting objects:  27% (23/85)\u001b[K\rremote: Counting objects:  28% (24/85)\u001b[K\rremote: Counting objects:  29% (25/85)\u001b[K\rremote: Counting objects:  30% (26/85)\u001b[K\rremote: Counting objects:  31% (27/85)\u001b[K\rremote: Counting objects:  32% (28/85)\u001b[K\rremote: Counting objects:  34% (29/85)\u001b[K\rremote: Counting objects:  35% (30/85)\u001b[K\rremote: Counting objects:  36% (31/85)\u001b[K\rremote: Counting objects:  37% (32/85)\u001b[K\rremote: Counting objects:  38% (33/85)\u001b[K\rremote: Counting objects:  40% (34/85)\u001b[K\rremote: Counting objects:  41% (35/85)\u001b[K\rremote: Counting objects:  42% (36/85)\u001b[K\rremote: Counting objects:  43% (37/85)\u001b[K\rremote: Counting objects:  44% (38/85)\u001b[K\rremote: Counting objects:  45% (39/85)\u001b[K\rremote: Counting objects:  47% (40/85)\u001b[K\rremote: Counting objects:  48% (41/85)\u001b[K\rremote: Counting objects:  49% (42/85)\u001b[K\rremote: Counting objects:  50% (43/85)\u001b[K\rremote: Counting objects:  51% (44/85)\u001b[K\rremote: Counting objects:  52% (45/85)\u001b[K\rremote: Counting objects:  54% (46/85)\u001b[K\rremote: Counting objects:  55% (47/85)\u001b[K\rremote: Counting objects:  56% (48/85)\u001b[K\rremote: Counting objects:  57% (49/85)\u001b[K\rremote: Counting objects:  58% (50/85)\u001b[K\rremote: Counting objects:  60% (51/85)\u001b[K\rremote: Counting objects:  61% (52/85)\u001b[K\rremote: Counting objects:  62% (53/85)\u001b[K\rremote: Counting objects:  63% (54/85)\u001b[K\rremote: Counting objects:  64% (55/85)\u001b[K\rremote: Counting objects:  65% (56/85)\u001b[K\rremote: Counting objects:  67% (57/85)\u001b[K\rremote: Counting objects:  68% (58/85)\u001b[K\rremote: Counting objects:  69% (59/85)\u001b[K\rremote: Counting objects:  70% (60/85)\u001b[K\rremote: Counting objects:  71% (61/85)\u001b[K\rremote: Counting objects:  72% (62/85)\u001b[K\rremote: Counting objects:  74% (63/85)\u001b[K\rremote: Counting objects:  75% (64/85)\u001b[K\rremote: Counting objects:  76% (65/85)\u001b[K\rremote: Counting objects:  77% (66/85)\u001b[K\rremote: Counting objects:  78% (67/85)\u001b[K\rremote: Counting objects:  80% (68/85)\u001b[K\rremote: Counting objects:  81% (69/85)\u001b[K\rremote: Counting objects:  82% (70/85)\u001b[K\rremote: Counting objects:  83% (71/85)\u001b[K\rremote: Counting objects:  84% (72/85)\u001b[K\rremote: Counting objects:  85% (73/85)\u001b[K\rremote: Counting objects:  87% (74/85)\u001b[K\rremote: Counting objects:  88% (75/85)\u001b[K\rremote: Counting objects:  89% (76/85)\u001b[K\rremote: Counting objects:  90% (77/85)\u001b[K\rremote: Counting objects:  91% (78/85)\u001b[K\rremote: Counting objects:  92% (79/85)\u001b[K\rremote: Counting objects:  94% (80/85)\u001b[K\rremote: Counting objects:  95% (81/85)\u001b[K\rremote: Counting objects:  96% (82/85)\u001b[K\rremote: Counting objects:  97% (83/85)\u001b[K\rremote: Counting objects:  98% (84/85)\u001b[K\rremote: Counting objects: 100% (85/85)\u001b[K\rremote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 328 (delta 50), reused 62 (delta 34), pack-reused 243\u001b[K\n",
            "Receiving objects: 100% (328/328), 5.98 MiB | 19.56 MiB/s, done.\n",
            "Resolving deltas: 100% (181/181), done.\n",
            "/content/bachelor_design\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S4uVkxeL8uOL",
        "outputId": "43e948c9-9df3-458a-c262-cda75215cb67",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "!git checkout equal_realize\n",
        "!git pull"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Branch 'equal_realize' set up to track remote branch 'equal_realize' from 'origin'.\n",
            "Switched to a new branch 'equal_realize'\n",
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gdgaaQWTo_Qm"
      },
      "source": [
        "# Mount GDriver\n",
        "Perpare Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XuNfDlfh4v4-",
        "outputId": "effee565-a3f1-46b0-d06f-cb3838b9c4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from driver_amount import addh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "[Colab] Using address head: /gdrive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DBCO9_n6abM",
        "colab_type": "text"
      },
      "source": [
        "# Load Params"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt34yXgY6dUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_LJ3yrB6y2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_vocab = None\n",
        "with open(addh + config.TAG_VOCAB_PATH, \"r\") as fd:\n",
        "  tag_vocab = json.load(fd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yKeEl1EWo_Q6"
      },
      "source": [
        "# Prepare Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "318x_FrYo_Q8",
        "colab": {}
      },
      "source": [
        "from cut_and_tag import cut_and_tag\n",
        "import preprocess"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nb-5so9mo_RC",
        "outputId": "336c1120-6d4c-43b0-c774-4a90047ca7ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "cut_seqs, char_seqs, tag_seqs = cut_and_tag(\n",
        "    addh + config.DATA_PATH,\n",
        "    addh + config.STOPWORDS_PATH\n",
        ")\n",
        "char_seqs, tag_seqs = preprocess.shuffle_twin(\n",
        "    char_seqs,\n",
        "    tag_seqs\n",
        ")\n",
        "token_id_seqs, segment_seqs, tag_id_seqs, tag_vocab = preprocess.preprocess(\n",
        "    char_seqs, \n",
        "    tag_seqs,\n",
        "    addh + config.BERT_VOCAB_PATH,\n",
        "    SEQ_LEN=config.SEQ_LEN,\n",
        "    tag_vocab=tag_vocab\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.792 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je_ajx6J2ml4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split train and text\n",
        "train_num = int(len(token_id_seqs) * 0.9)\n",
        "\n",
        "test_token_id_seqs = token_id_seqs[train_num:]\n",
        "test_segment_seqs = segment_seqs[train_num:]\n",
        "test_tag_id_seqs = tag_id_seqs[train_num:]\n",
        "\n",
        "train_token_id_seqs = token_id_seqs[0:train_num]\n",
        "train_segment_seqs = segment_seqs[0:train_num]\n",
        "train_tag_id_seqs = tag_id_seqs[0:train_num]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XLj4Kcwko_RW",
        "outputId": "912971f2-7fc5-4d1e-f446-59446ac33e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "tag_vocab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'': 0,\n",
              " 'B-EI': 2,\n",
              " 'B-EIF': 10,\n",
              " 'B-EO': 6,\n",
              " 'B-EQ': 8,\n",
              " 'B-ILF': 4,\n",
              " 'I-EI': 3,\n",
              " 'I-EIF': 11,\n",
              " 'I-EO': 7,\n",
              " 'I-EQ': 9,\n",
              " 'I-ILF': 5,\n",
              " 'O': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wv1zgY3lo_Rb"
      },
      "source": [
        "# Build Model\n",
        "using BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QVZYwuGro_Rc",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import keras_bert "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tBszsRPVo_Rh",
        "outputId": "da65794a-35a0-408d-b5ac-75c52f014012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "bert_model, bert_model_config = keras_bert.build_model_from_config(\n",
        "    # config_file\n",
        "    addh + config.BERT_CONFIG_PATH, \n",
        "    # settings\n",
        "    training=False, # Not train the whole model. Ignore NSP and MLM\n",
        "    trainable=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KRVUQ-dDfW0F",
        "colab": {}
      },
      "source": [
        "from keras_contrib.layers import CRF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7riudikwo_Rm",
        "colab": {}
      },
      "source": [
        "input_token = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
        "input_segment = keras.layers.Input(shape=(config.SEQ_LEN,))\n",
        "\n",
        "bert_output = bert_model([input_token, input_segment])\n",
        "\n",
        "crf_model = CRF(len(tag_vocab), sparse_target=True)\n",
        "\n",
        "output = crf_model(bert_output)\n",
        "\n",
        "model = keras.models.Model([input_token, input_segment], output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux9lxZyJ2mmO",
        "colab_type": "code",
        "outputId": "6be901de-2485-4ece-d5ae-4ef196f7be87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "model.load_weights(addh + config.MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt34Q-VO2mmR",
        "colab_type": "text"
      },
      "source": [
        "# Load train record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bjsOu942mmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open(addh + config.TRAIN_REC_PATH, \"r\") as fd:\n",
        "    train_rec = json.load(fd)\n",
        "last_epoch = 0\n",
        "if len(train_rec) > 1:\n",
        "    last_epoch = train_rec[-1][\"epoch\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1NnstgM3o_Rx"
      },
      "source": [
        "# Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PZnpZmJ9o_Ry",
        "outputId": "35d11f62-77dd-47ae-f3b3-4cefd715141c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(lr=0.00004),\n",
        "    loss=crf_model.loss_function,\n",
        "    metrics=[crf_model.accuracy]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_ops.py:2509: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
            "  warnings.warn('CRF.loss_function is deprecated '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_contrib/layers/crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
            "  warnings.warn('CRF.accuracy is deprecated and it '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KFQwbTXw4v6G",
        "colab": {}
      },
      "source": [
        "import epoch_checkpoint\n",
        "epoch_callback = epoch_checkpoint.EpochCheckpoint(\n",
        "    addh + config.MODEL_PATH,\n",
        "    addh + config.TRAIN_REC_PATH,\n",
        "    1,\n",
        "    [test_token_id_seqs, test_segment_seqs],\n",
        "    test_tag_id_seqs,\n",
        "    tag_vocab\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3wC8aDwfJLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "completed = False\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fiWLYOZHo_R3",
        "outputId": "6de625c7-953c-49e1-b563-5d7005451d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "while not completed:\n",
        "  try:\n",
        "    model.fit(\n",
        "        x=[train_token_id_seqs, train_segment_seqs],\n",
        "        y=[train_tag_id_seqs], \n",
        "        batch_size=8,\n",
        "        initial_epoch=last_epoch+1,\n",
        "        epochs=train_rec[0][\"train_params\"][\"epochs\"],\n",
        "        verbose=1,\n",
        "        validation_data=[[test_token_id_seqs, test_segment_seqs], [test_tag_id_seqs]],\n",
        "        callbacks=[epoch_callback]\n",
        "    )\n",
        "    completed = True\n",
        "  except tf.errors.ResourceExhaustedError:\n",
        "    batch_size /= 2\n",
        "    print(\"Batch Size too large, turn to \" + str(batch_size))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7005 samples, validate on 779 samples\n",
            "Epoch 7/15\n",
            "Batch Size too large, turn to 8\n",
            "Train on 7005 samples, validate on 779 samples\n",
            "Epoch 7/15\n",
            "Batch Size too large, turn to 4\n",
            "Train on 7005 samples, validate on 779 samples\n",
            "Epoch 7/15\n",
            "Batch Size too large, turn to 2\n",
            "Train on 7005 samples, validate on 779 samples\n",
            "Epoch 7/15\n",
            "7005/7005 [==============================] - 5147s 735ms/step - loss: 55.7178 - crf_viterbi_accuracy: 0.9053 - val_loss: 55.4849 - val_crf_viterbi_accuracy: 0.9115\n",
            "Saving checkpint...\n",
            "Predicing for matrics calculating...\n",
            "779/779 [==============================] - 202s 260ms/step\n",
            "Updating train record...\n",
            "Epoch 8/15\n",
            " 942/7005 [===>..........................] - ETA: 1:11:47 - loss: 55.2049 - crf_viterbi_accuracy: 0.9289"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4a338c5fec33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_token_id_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_segment_seqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtest_tag_id_seqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[0mcompleted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zp-wuH9RBk3r",
        "colab": {}
      },
      "source": [
        "model.save(addh + config.MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}