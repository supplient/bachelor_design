{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_bert\n",
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Locale] Using address head: /mnt/d/My Drive\n"
     ]
    }
   ],
   "source": [
    "from driver_amount import addh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/supplient/bachelor_design.git\n",
    "import os\n",
    "os.chdir(\"bachelor_design\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout equal_realize\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origin Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import load_file\n",
    "import config\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_seqs, tag_seqs = load_file(addh + config.DATA_PATH)\n",
    "equal_seqs = None\n",
    "with open(addh + config.EQUAL_DATA_PATH, \"r\") as fd:\n",
    "    equal_seqs = json.load(fd)\n",
    "origin_seqs = char_seqs[:len(equal_seqs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Param Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "params = None\n",
    "# TODO the better way to do this is \n",
    "#    check whether the file exists first,\n",
    "#    then create it and set default params when it does not exist.\n",
    "params = {}\n",
    "with open(addh + config.EQUAL_PARAM_PATH, \"r\") as fd:\n",
    "    params = json.load(fd)\n",
    "    \n",
    "sif_alpha = params[\"sif_alpha\"]\n",
    "\n",
    "cos_theta = params[\"cos_theta\"]\n",
    "\n",
    "dist_theta = cos_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our embedding is designed for batch work, it should be better if we combine origin_seqs and equal_seqs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_num = len(origin_seqs)\n",
    "all_char_seqs = []\n",
    "all_char_seqs.extend(origin_seqs)\n",
    "all_char_seqs.extend(equal_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from char_emb import CharEmbedder\n",
    "from SIF import SIF\n",
    "from dist_cal import DistCal\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rec = {}\n",
    "char_embedder = CharEmbedder()\n",
    "sif = SIF(sif_alpha)\n",
    "dist_caler = DistCal(all_char_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dist_method in tqdm(DistCal.methods, desc=\"Distance\"):\n",
    "    dist_theta = params.get(dist_method + \"_theta\", None)\n",
    "    for emb_method in tqdm(CharEmbedder.methods, desc=\"Char embed\", leave=False):\n",
    "        # Embedding\n",
    "        all_char_emb_seqs = char_embedder.embed(all_char_seqs)\n",
    "        all_sen_vecs = sif.compose(all_char_seqs, all_char_emb_seqs)\n",
    "        \n",
    "        # Split\n",
    "        origin_sen_vecs = all_sen_vecs[:origin_num]\n",
    "        equal_sen_vecs = all_sen_vecs[origin_num:]\n",
    "        if len(origin_sen_vecs) != len(equal_sen_vecs):\n",
    "            raise Exception(\"Length should be the same.\")\n",
    "            \n",
    "        # Train theta\n",
    "        ## Set train params\n",
    "        epoch = 10000\n",
    "        delta = 0.001\n",
    "        min_delta = 10**(-10)\n",
    "        \n",
    "        ## Use two experiments\n",
    "        ## * Check whether origin and equal are similiar\n",
    "        ## * Check whether origins are different\n",
    "        N = len(origin_sen_vecs)\n",
    "        similiar_total = N # TP + FN\n",
    "        different_total = N * (N -1)/2 # FP + TN\n",
    "        \n",
    "        similiar_count = 0 # TP\n",
    "        different_count = 0 # TN\n",
    "        last_delta = 0\n",
    "        with trange(epoch, desc=\"Train theta\", leave=False) as epoch_tqdm:\n",
    "            for epoch_count in epoch_tqdm:\n",
    "                # Do experiments\n",
    "                similiar_count = 0\n",
    "                for origin_sen, equal_sen in zip(origin_sen_vecs, equal_sen_vecs):\n",
    "                    dist = dist_cal.cal(origin_sen, equal_sen)\n",
    "                    if dist < dist_theta:\n",
    "                        similiar_count += 1\n",
    "                    if dist_theta == None: # When dist_theta is not set, take the first dist as its initial value\n",
    "                        dist_theta = dist\n",
    "\n",
    "                different_count = 0\n",
    "                for i in range(N-1):\n",
    "                    for j in range(i+1, N):\n",
    "                        dist = dist_cal.cal(origin_sen_vecs[i], origin_sen_vecs[j])\n",
    "                        if dist > dist_theta:\n",
    "                            different_count += 1\n",
    "\n",
    "                similiar_rate = similiar_count / similiar_total\n",
    "                different_rate = different_count / different_total\n",
    "\n",
    "                # Finetune theta\n",
    "                now_delta = 0\n",
    "                if similiar_rate > different_rate:\n",
    "                    now_delta = -delta\n",
    "                elif similiar_rate < different_rate:\n",
    "                    now_delta = delta\n",
    "                else:\n",
    "                    now_delta = -last_delta\n",
    "\n",
    "                if now_delta == -last_delta:\n",
    "                    delta /= 10\n",
    "                    now_delta /= 10\n",
    "                dist_theta += now_delta\n",
    "                last_delta = now_delta\n",
    "\n",
    "                if dist_theta <= 0:\n",
    "                    raise Exception(\"dist_theta reach 0\")\n",
    "                if dist_theta >= 1:\n",
    "                    raise Exception(\"dist_theta reach 1\")\n",
    "\n",
    "                # Update progroess info\n",
    "                epoch_tqdm.set_description(\"Epoch %i\" % epoch_count)\n",
    "                epoch_tqdm.set_postfix(\n",
    "                    similiar_rate=similiar_rate, \n",
    "                    different_rate=different_rate,\n",
    "                    dist_theta=dist_theta,\n",
    "                    delta=delta\n",
    "                )\n",
    "\n",
    "                # Stop when delta's precision is enough\n",
    "                if delta <= min_delta:\n",
    "                    epoch_tqdm.write(\"Delta reach \" + str(min_delta) + \", which is enough\")\n",
    "                    break\n",
    "        \n",
    "        # Cache train records\n",
    "        if not train_rec.get(dist_method, None):\n",
    "            train_rec[dist_method] = {}\n",
    "        train_rec[dist_method][emb_method] = {\n",
    "            \"TP\": similiar_count,\n",
    "            \"FP\": different_total - different_count,\n",
    "            \"FN\": similiar_total - similiar_count,\n",
    "            \"TN\": different_count,\n",
    "            \"dist_theta\": dist_theta\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze train record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for drawing table\n",
    "dist_labels = []\n",
    "emb_labels = []\n",
    "table_vals = []\n",
    "\n",
    "for dist_method in train_rec.keys():\n",
    "    dist_labels.append(dist_method)\n",
    "    table_vals.append([])\n",
    "    for emb_method in train_rec[dist_method].keys():\n",
    "        emb_labels.append(emb_method)\n",
    "        rec = train_rec[dist_method][emb_method]\n",
    "        p = rec[\"TP\"]/(rec[\"TP\"] + rec[\"FP\"])\n",
    "        r = rec[\"TP\"]/(rec[\"TP\"] + rec[\"FN\"])\n",
    "        f1 = 2*p*r / (p+r)\n",
    "        rec[\"precision\"] = p\n",
    "        rec[\"recall\"] = r\n",
    "        rec[\"F1\"] = f1\n",
    "        \n",
    "        table_vals[-1].append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "| F1 |  e1 |  e2 |\n",
      "+----+-----+-----+\n",
      "| d1 | 0.4 | 0.4 |\n",
      "+----+-----+-----+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "header = [\"F1\"]\n",
    "header.extend(emb_labels)\n",
    "t = PrettyTable(\n",
    "    field_names=header,\n",
    "    header=True\n",
    ")\n",
    "for i in range(len(dist_labels)):\n",
    "    row = [dist_labels[i]]\n",
    "    row.extend(table_vals[i])\n",
    "    t.add_row(row)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save train record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(addh + config.EQUAL_TRAIN_REC_PATH, \"w\") as fd:\n",
    "    json.dump(train_rec, fd, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
